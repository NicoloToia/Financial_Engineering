{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4 Group 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T14:45:04.697745Z",
     "start_time": "2024-03-19T14:45:04.679348Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import t\n",
    "from scipy.stats import norm\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import our custom functions\n",
    "from Assignment4_lib import HSMeasurements, bootstrapStatistical, WHSMeasurements, \\\n",
    "    PrincCompAnalysis, plausibilityCheck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix the random seed\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data from the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T14:45:04.861854Z",
     "start_time": "2024-03-19T14:45:04.845110Z"
    }
   },
   "outputs": [],
   "source": [
    "# load the indexes as dictionary of {ticker: name}\n",
    "with open('data/_indexes.csv', 'r') as f:\n",
    "    # skip the first line\n",
    "    indexes = {\n",
    "        line.split(',')[1]: line.split(',')[2].strip()\n",
    "        for line in f.readlines()[1:]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T14:45:04.969685Z",
     "start_time": "2024-03-19T14:45:04.890495Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ABI.BR</th>\n",
       "      <th>AD.AS</th>\n",
       "      <th>ADSGn.DE</th>\n",
       "      <th>ADYEN.AS</th>\n",
       "      <th>AIR.PA</th>\n",
       "      <th>AIRP.PA</th>\n",
       "      <th>ALVG.DE</th>\n",
       "      <th>ASML.AS</th>\n",
       "      <th>AXAF.PA</th>\n",
       "      <th>BASFn.DE</th>\n",
       "      <th>...</th>\n",
       "      <th>SAN.MC</th>\n",
       "      <th>SAPG.DE</th>\n",
       "      <th>SASY.PA</th>\n",
       "      <th>SCHN.PA</th>\n",
       "      <th>SGEF.PA</th>\n",
       "      <th>SIEGn.DE</th>\n",
       "      <th>STLAM.MI</th>\n",
       "      <th>TTEF.PA</th>\n",
       "      <th>VNAn.DE</th>\n",
       "      <th>VOWG_p.DE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-02</th>\n",
       "      <td>67.35</td>\n",
       "      <td>10.344663</td>\n",
       "      <td>67.48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.065</td>\n",
       "      <td>63.872086</td>\n",
       "      <td>108.30</td>\n",
       "      <td>50.170</td>\n",
       "      <td>13.810</td>\n",
       "      <td>73.18</td>\n",
       "      <td>...</td>\n",
       "      <td>4.642466</td>\n",
       "      <td>61.740795</td>\n",
       "      <td>72.619232</td>\n",
       "      <td>56.69</td>\n",
       "      <td>36.477679</td>\n",
       "      <td>73.202953</td>\n",
       "      <td>1.859794</td>\n",
       "      <td>39.975</td>\n",
       "      <td>NaN</td>\n",
       "      <td>179.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-03</th>\n",
       "      <td>66.54</td>\n",
       "      <td>10.344663</td>\n",
       "      <td>67.18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.200</td>\n",
       "      <td>63.433011</td>\n",
       "      <td>108.00</td>\n",
       "      <td>50.340</td>\n",
       "      <td>13.825</td>\n",
       "      <td>72.35</td>\n",
       "      <td>...</td>\n",
       "      <td>4.626329</td>\n",
       "      <td>61.661232</td>\n",
       "      <td>72.430223</td>\n",
       "      <td>56.45</td>\n",
       "      <td>36.636105</td>\n",
       "      <td>73.255365</td>\n",
       "      <td>1.886567</td>\n",
       "      <td>39.855</td>\n",
       "      <td>NaN</td>\n",
       "      <td>178.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-04</th>\n",
       "      <td>67.62</td>\n",
       "      <td>10.465124</td>\n",
       "      <td>66.72</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.800</td>\n",
       "      <td>63.499538</td>\n",
       "      <td>108.20</td>\n",
       "      <td>49.755</td>\n",
       "      <td>13.865</td>\n",
       "      <td>72.47</td>\n",
       "      <td>...</td>\n",
       "      <td>4.643200</td>\n",
       "      <td>61.134128</td>\n",
       "      <td>73.285737</td>\n",
       "      <td>56.43</td>\n",
       "      <td>36.754925</td>\n",
       "      <td>73.316513</td>\n",
       "      <td>1.917165</td>\n",
       "      <td>39.820</td>\n",
       "      <td>NaN</td>\n",
       "      <td>178.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-07</th>\n",
       "      <td>66.93</td>\n",
       "      <td>10.530375</td>\n",
       "      <td>66.28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.750</td>\n",
       "      <td>62.973979</td>\n",
       "      <td>107.70</td>\n",
       "      <td>48.750</td>\n",
       "      <td>13.905</td>\n",
       "      <td>71.64</td>\n",
       "      <td>...</td>\n",
       "      <td>4.637332</td>\n",
       "      <td>60.616969</td>\n",
       "      <td>72.997250</td>\n",
       "      <td>56.10</td>\n",
       "      <td>36.403416</td>\n",
       "      <td>73.045715</td>\n",
       "      <td>1.919078</td>\n",
       "      <td>39.155</td>\n",
       "      <td>NaN</td>\n",
       "      <td>175.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-08</th>\n",
       "      <td>65.90</td>\n",
       "      <td>10.460105</td>\n",
       "      <td>66.36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.925</td>\n",
       "      <td>62.767747</td>\n",
       "      <td>107.05</td>\n",
       "      <td>48.220</td>\n",
       "      <td>13.575</td>\n",
       "      <td>71.14</td>\n",
       "      <td>...</td>\n",
       "      <td>4.650535</td>\n",
       "      <td>60.318608</td>\n",
       "      <td>73.365320</td>\n",
       "      <td>56.12</td>\n",
       "      <td>36.304400</td>\n",
       "      <td>72.556530</td>\n",
       "      <td>1.895173</td>\n",
       "      <td>39.385</td>\n",
       "      <td>NaN</td>\n",
       "      <td>174.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ABI.BR      AD.AS  ADSGn.DE  ADYEN.AS  AIR.PA    AIRP.PA  ALVG.DE  \\\n",
       "Date                                                                            \n",
       "2013-01-02   67.35  10.344663     67.48       NaN  30.065  63.872086   108.30   \n",
       "2013-01-03   66.54  10.344663     67.18       NaN  30.200  63.433011   108.00   \n",
       "2013-01-04   67.62  10.465124     66.72       NaN  30.800  63.499538   108.20   \n",
       "2013-01-07   66.93  10.530375     66.28       NaN  30.750  62.973979   107.70   \n",
       "2013-01-08   65.90  10.460105     66.36       NaN  30.925  62.767747   107.05   \n",
       "\n",
       "            ASML.AS  AXAF.PA  BASFn.DE  ...    SAN.MC    SAPG.DE    SASY.PA  \\\n",
       "Date                                    ...                                   \n",
       "2013-01-02   50.170   13.810     73.18  ...  4.642466  61.740795  72.619232   \n",
       "2013-01-03   50.340   13.825     72.35  ...  4.626329  61.661232  72.430223   \n",
       "2013-01-04   49.755   13.865     72.47  ...  4.643200  61.134128  73.285737   \n",
       "2013-01-07   48.750   13.905     71.64  ...  4.637332  60.616969  72.997250   \n",
       "2013-01-08   48.220   13.575     71.14  ...  4.650535  60.318608  73.365320   \n",
       "\n",
       "            SCHN.PA    SGEF.PA   SIEGn.DE  STLAM.MI  TTEF.PA  VNAn.DE  \\\n",
       "Date                                                                    \n",
       "2013-01-02    56.69  36.477679  73.202953  1.859794   39.975      NaN   \n",
       "2013-01-03    56.45  36.636105  73.255365  1.886567   39.855      NaN   \n",
       "2013-01-04    56.43  36.754925  73.316513  1.917165   39.820      NaN   \n",
       "2013-01-07    56.10  36.403416  73.045715  1.919078   39.155      NaN   \n",
       "2013-01-08    56.12  36.304400  72.556530  1.895173   39.385      NaN   \n",
       "\n",
       "            VOWG_p.DE  \n",
       "Date                   \n",
       "2013-01-02     179.00  \n",
       "2013-01-03     178.90  \n",
       "2013-01-04     178.85  \n",
       "2013-01-07     175.95  \n",
       "2013-01-08     174.00  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the actual dataset as a dataframe\n",
    "EuroStoxx50 = pd.read_csv('data/EUROSTOXX50_Dataset.csv', sep=',')\n",
    "EuroStoxx50 = EuroStoxx50.set_index(pd.DatetimeIndex(EuroStoxx50['Date']))\n",
    "EuroStoxx50 = EuroStoxx50.drop('Date', axis=1)\n",
    "EuroStoxx50.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T14:45:05.173204Z",
     "start_time": "2024-03-19T14:45:04.973188Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ABI.BR</th>\n",
       "      <th>AD.AS</th>\n",
       "      <th>ADSGn.DE</th>\n",
       "      <th>ADYEN.AS</th>\n",
       "      <th>AIR.PA</th>\n",
       "      <th>AIRP.PA</th>\n",
       "      <th>ALVG.DE</th>\n",
       "      <th>ASML.AS</th>\n",
       "      <th>AXAF.PA</th>\n",
       "      <th>BASFn.DE</th>\n",
       "      <th>...</th>\n",
       "      <th>SAN.MC</th>\n",
       "      <th>SAPG.DE</th>\n",
       "      <th>SASY.PA</th>\n",
       "      <th>SCHN.PA</th>\n",
       "      <th>SGEF.PA</th>\n",
       "      <th>SIEGn.DE</th>\n",
       "      <th>STLAM.MI</th>\n",
       "      <th>TTEF.PA</th>\n",
       "      <th>VNAn.DE</th>\n",
       "      <th>VOWG_p.DE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2595.000000</td>\n",
       "      <td>2595.000000</td>\n",
       "      <td>2568.000000</td>\n",
       "      <td>1204.000000</td>\n",
       "      <td>2595.000000</td>\n",
       "      <td>2595.000000</td>\n",
       "      <td>2568.000000</td>\n",
       "      <td>2595.000000</td>\n",
       "      <td>2595.000000</td>\n",
       "      <td>2568.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2593.000000</td>\n",
       "      <td>2568.000000</td>\n",
       "      <td>2595.000000</td>\n",
       "      <td>2595.000000</td>\n",
       "      <td>2595.000000</td>\n",
       "      <td>2568.000000</td>\n",
       "      <td>2574.000000</td>\n",
       "      <td>2595.000000</td>\n",
       "      <td>2435.000000</td>\n",
       "      <td>2568.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>78.466609</td>\n",
       "      <td>20.222655</td>\n",
       "      <td>168.117960</td>\n",
       "      <td>1313.152865</td>\n",
       "      <td>79.464584</td>\n",
       "      <td>94.856556</td>\n",
       "      <td>169.402371</td>\n",
       "      <td>228.457549</td>\n",
       "      <td>21.497944</td>\n",
       "      <td>69.981291</td>\n",
       "      <td>...</td>\n",
       "      <td>4.117864</td>\n",
       "      <td>87.953312</td>\n",
       "      <td>80.714696</td>\n",
       "      <td>83.908960</td>\n",
       "      <td>72.686856</td>\n",
       "      <td>99.203473</td>\n",
       "      <td>8.653848</td>\n",
       "      <td>44.765356</td>\n",
       "      <td>34.876696</td>\n",
       "      <td>159.223306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>22.017982</td>\n",
       "      <td>4.959865</td>\n",
       "      <td>78.600789</td>\n",
       "      <td>634.775495</td>\n",
       "      <td>27.851830</td>\n",
       "      <td>25.424532</td>\n",
       "      <td>34.043809</td>\n",
       "      <td>192.493032</td>\n",
       "      <td>3.408427</td>\n",
       "      <td>13.209816</td>\n",
       "      <td>...</td>\n",
       "      <td>1.239889</td>\n",
       "      <td>23.157071</td>\n",
       "      <td>7.999882</td>\n",
       "      <td>31.224451</td>\n",
       "      <td>18.878874</td>\n",
       "      <td>20.444696</td>\n",
       "      <td>4.366842</td>\n",
       "      <td>6.105825</td>\n",
       "      <td>11.245108</td>\n",
       "      <td>31.092819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>30.970000</td>\n",
       "      <td>10.344663</td>\n",
       "      <td>53.890000</td>\n",
       "      <td>411.000000</td>\n",
       "      <td>30.065000</td>\n",
       "      <td>59.481338</td>\n",
       "      <td>101.750000</td>\n",
       "      <td>47.200000</td>\n",
       "      <td>12.494000</td>\n",
       "      <td>38.850000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.460862</td>\n",
       "      <td>50.621882</td>\n",
       "      <td>62.880297</td>\n",
       "      <td>45.930000</td>\n",
       "      <td>34.155742</td>\n",
       "      <td>54.880885</td>\n",
       "      <td>1.859794</td>\n",
       "      <td>21.795000</td>\n",
       "      <td>15.654411</td>\n",
       "      <td>87.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>56.970000</td>\n",
       "      <td>17.043070</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>680.150000</td>\n",
       "      <td>53.915000</td>\n",
       "      <td>72.103553</td>\n",
       "      <td>138.450000</td>\n",
       "      <td>85.510000</td>\n",
       "      <td>18.907000</td>\n",
       "      <td>62.605000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.176468</td>\n",
       "      <td>65.689103</td>\n",
       "      <td>74.653565</td>\n",
       "      <td>62.020000</td>\n",
       "      <td>56.315000</td>\n",
       "      <td>84.843162</td>\n",
       "      <td>4.683985</td>\n",
       "      <td>40.917500</td>\n",
       "      <td>26.520376</td>\n",
       "      <td>137.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>76.300000</td>\n",
       "      <td>20.175000</td>\n",
       "      <td>172.775000</td>\n",
       "      <td>1366.000000</td>\n",
       "      <td>72.380000</td>\n",
       "      <td>87.479356</td>\n",
       "      <td>174.655000</td>\n",
       "      <td>148.500000</td>\n",
       "      <td>22.165000</td>\n",
       "      <td>69.815000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.009865</td>\n",
       "      <td>90.157344</td>\n",
       "      <td>79.801572</td>\n",
       "      <td>69.820000</td>\n",
       "      <td>77.220000</td>\n",
       "      <td>94.914723</td>\n",
       "      <td>7.764398</td>\n",
       "      <td>45.280000</td>\n",
       "      <td>33.500000</td>\n",
       "      <td>153.630000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>98.465000</td>\n",
       "      <td>23.472500</td>\n",
       "      <td>235.137500</td>\n",
       "      <td>1789.000000</td>\n",
       "      <td>105.010000</td>\n",
       "      <td>120.072733</td>\n",
       "      <td>198.460000</td>\n",
       "      <td>317.450000</td>\n",
       "      <td>23.967500</td>\n",
       "      <td>80.377500</td>\n",
       "      <td>...</td>\n",
       "      <td>5.202168</td>\n",
       "      <td>105.045614</td>\n",
       "      <td>86.635739</td>\n",
       "      <td>102.875000</td>\n",
       "      <td>88.310000</td>\n",
       "      <td>108.752134</td>\n",
       "      <td>12.067848</td>\n",
       "      <td>48.572500</td>\n",
       "      <td>43.469417</td>\n",
       "      <td>179.927500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>123.250000</td>\n",
       "      <td>31.090000</td>\n",
       "      <td>336.250000</td>\n",
       "      <td>2766.000000</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>150.600015</td>\n",
       "      <td>232.000000</td>\n",
       "      <td>770.500000</td>\n",
       "      <td>28.830000</td>\n",
       "      <td>97.670000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.771846</td>\n",
       "      <td>141.482691</td>\n",
       "      <td>105.665956</td>\n",
       "      <td>177.820000</td>\n",
       "      <td>109.540000</td>\n",
       "      <td>157.960000</td>\n",
       "      <td>19.140000</td>\n",
       "      <td>60.710000</td>\n",
       "      <td>58.327952</td>\n",
       "      <td>255.200000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ABI.BR        AD.AS     ADSGn.DE     ADYEN.AS       AIR.PA  \\\n",
       "count  2595.000000  2595.000000  2568.000000  1204.000000  2595.000000   \n",
       "mean     78.466609    20.222655   168.117960  1313.152865    79.464584   \n",
       "std      22.017982     4.959865    78.600789   634.775495    27.851830   \n",
       "min      30.970000    10.344663    53.890000   411.000000    30.065000   \n",
       "25%      56.970000    17.043070    85.000000   680.150000    53.915000   \n",
       "50%      76.300000    20.175000   172.775000  1366.000000    72.380000   \n",
       "75%      98.465000    23.472500   235.137500  1789.000000   105.010000   \n",
       "max     123.250000    31.090000   336.250000  2766.000000   139.000000   \n",
       "\n",
       "           AIRP.PA      ALVG.DE      ASML.AS      AXAF.PA     BASFn.DE  ...  \\\n",
       "count  2595.000000  2568.000000  2595.000000  2595.000000  2568.000000  ...   \n",
       "mean     94.856556   169.402371   228.457549    21.497944    69.981291  ...   \n",
       "std      25.424532    34.043809   192.493032     3.408427    13.209816  ...   \n",
       "min      59.481338   101.750000    47.200000    12.494000    38.850000  ...   \n",
       "25%      72.103553   138.450000    85.510000    18.907000    62.605000  ...   \n",
       "50%      87.479356   174.655000   148.500000    22.165000    69.815000  ...   \n",
       "75%     120.072733   198.460000   317.450000    23.967500    80.377500  ...   \n",
       "max     150.600015   232.000000   770.500000    28.830000    97.670000  ...   \n",
       "\n",
       "            SAN.MC      SAPG.DE      SASY.PA      SCHN.PA      SGEF.PA  \\\n",
       "count  2593.000000  2568.000000  2595.000000  2595.000000  2595.000000   \n",
       "mean      4.117864    87.953312    80.714696    83.908960    72.686856   \n",
       "std       1.239889    23.157071     7.999882    31.224451    18.878874   \n",
       "min       1.460862    50.621882    62.880297    45.930000    34.155742   \n",
       "25%       3.176468    65.689103    74.653565    62.020000    56.315000   \n",
       "50%       4.009865    90.157344    79.801572    69.820000    77.220000   \n",
       "75%       5.202168   105.045614    86.635739   102.875000    88.310000   \n",
       "max       6.771846   141.482691   105.665956   177.820000   109.540000   \n",
       "\n",
       "          SIEGn.DE     STLAM.MI      TTEF.PA      VNAn.DE    VOWG_p.DE  \n",
       "count  2568.000000  2574.000000  2595.000000  2435.000000  2568.000000  \n",
       "mean     99.203473     8.653848    44.765356    34.876696   159.223306  \n",
       "std      20.444696     4.366842     6.105825    11.245108    31.092819  \n",
       "min      54.880885     1.859794    21.795000    15.654411    87.200000  \n",
       "25%      84.843162     4.683985    40.917500    26.520376   137.600000  \n",
       "50%      94.914723     7.764398    45.280000    33.500000   153.630000  \n",
       "75%     108.752134    12.067848    48.572500    43.469417   179.927500  \n",
       "max     157.960000    19.140000    60.710000    58.327952   255.200000  \n",
       "\n",
       "[8 rows x 50 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summarize the dataset\n",
    "EuroStoxx50.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T14:45:05.188649Z",
     "start_time": "2024-03-19T14:45:05.175808Z"
    }
   },
   "outputs": [],
   "source": [
    "# drop the columns that only contain NaN\n",
    "EuroStoxx50 = EuroStoxx50.dropna(axis=1, how='all')\n",
    "# for those who have NaN, fill them with the previous value\n",
    "EuroStoxx50 = EuroStoxx50.ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T14:45:05.240154Z",
     "start_time": "2024-03-19T14:45:05.196969Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ABI.BR</th>\n",
       "      <th>AD.AS</th>\n",
       "      <th>ADSGn.DE</th>\n",
       "      <th>ADYEN.AS</th>\n",
       "      <th>AIR.PA</th>\n",
       "      <th>AIRP.PA</th>\n",
       "      <th>ALVG.DE</th>\n",
       "      <th>ASML.AS</th>\n",
       "      <th>AXAF.PA</th>\n",
       "      <th>BASFn.DE</th>\n",
       "      <th>...</th>\n",
       "      <th>SAN.MC</th>\n",
       "      <th>SAPG.DE</th>\n",
       "      <th>SASY.PA</th>\n",
       "      <th>SCHN.PA</th>\n",
       "      <th>SGEF.PA</th>\n",
       "      <th>SIEGn.DE</th>\n",
       "      <th>STLAM.MI</th>\n",
       "      <th>TTEF.PA</th>\n",
       "      <th>VNAn.DE</th>\n",
       "      <th>VOWG_p.DE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-03</th>\n",
       "      <td>-0.012100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.004456</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004480</td>\n",
       "      <td>-0.006898</td>\n",
       "      <td>-0.002774</td>\n",
       "      <td>0.003383</td>\n",
       "      <td>0.001086</td>\n",
       "      <td>-0.011407</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003482</td>\n",
       "      <td>-0.001289</td>\n",
       "      <td>-0.002606</td>\n",
       "      <td>-0.004243</td>\n",
       "      <td>0.004334</td>\n",
       "      <td>0.000716</td>\n",
       "      <td>0.014293</td>\n",
       "      <td>-0.003006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-04</th>\n",
       "      <td>0.016101</td>\n",
       "      <td>0.011578</td>\n",
       "      <td>-0.006871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.019673</td>\n",
       "      <td>0.001048</td>\n",
       "      <td>0.001850</td>\n",
       "      <td>-0.011689</td>\n",
       "      <td>0.002889</td>\n",
       "      <td>0.001657</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003640</td>\n",
       "      <td>-0.008585</td>\n",
       "      <td>0.011742</td>\n",
       "      <td>-0.000354</td>\n",
       "      <td>0.003238</td>\n",
       "      <td>0.000834</td>\n",
       "      <td>0.016089</td>\n",
       "      <td>-0.000879</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-07</th>\n",
       "      <td>-0.010257</td>\n",
       "      <td>0.006216</td>\n",
       "      <td>-0.006617</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.001625</td>\n",
       "      <td>-0.008311</td>\n",
       "      <td>-0.004632</td>\n",
       "      <td>-0.020406</td>\n",
       "      <td>0.002881</td>\n",
       "      <td>-0.011519</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001265</td>\n",
       "      <td>-0.008495</td>\n",
       "      <td>-0.003944</td>\n",
       "      <td>-0.005865</td>\n",
       "      <td>-0.009610</td>\n",
       "      <td>-0.003700</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>-0.016841</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.016348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-08</th>\n",
       "      <td>-0.015509</td>\n",
       "      <td>-0.006695</td>\n",
       "      <td>0.001206</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005675</td>\n",
       "      <td>-0.003280</td>\n",
       "      <td>-0.006054</td>\n",
       "      <td>-0.010931</td>\n",
       "      <td>-0.024019</td>\n",
       "      <td>-0.007004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002843</td>\n",
       "      <td>-0.004934</td>\n",
       "      <td>0.005030</td>\n",
       "      <td>0.000356</td>\n",
       "      <td>-0.002724</td>\n",
       "      <td>-0.006719</td>\n",
       "      <td>-0.012535</td>\n",
       "      <td>0.005857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.011145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-09</th>\n",
       "      <td>-0.018996</td>\n",
       "      <td>-0.005292</td>\n",
       "      <td>0.013174</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.038070</td>\n",
       "      <td>-0.002653</td>\n",
       "      <td>-0.018384</td>\n",
       "      <td>0.012571</td>\n",
       "      <td>0.005510</td>\n",
       "      <td>0.003788</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009575</td>\n",
       "      <td>0.006082</td>\n",
       "      <td>0.001490</td>\n",
       "      <td>0.001425</td>\n",
       "      <td>0.011794</td>\n",
       "      <td>0.002045</td>\n",
       "      <td>0.018991</td>\n",
       "      <td>0.003675</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.013889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ABI.BR     AD.AS  ADSGn.DE  ADYEN.AS    AIR.PA   AIRP.PA  \\\n",
       "Date                                                                     \n",
       "2013-01-03 -0.012100  0.000000 -0.004456       NaN  0.004480 -0.006898   \n",
       "2013-01-04  0.016101  0.011578 -0.006871       NaN  0.019673  0.001048   \n",
       "2013-01-07 -0.010257  0.006216 -0.006617       NaN -0.001625 -0.008311   \n",
       "2013-01-08 -0.015509 -0.006695  0.001206       NaN  0.005675 -0.003280   \n",
       "2013-01-09 -0.018996 -0.005292  0.013174       NaN  0.038070 -0.002653   \n",
       "\n",
       "             ALVG.DE   ASML.AS   AXAF.PA  BASFn.DE  ...    SAN.MC   SAPG.DE  \\\n",
       "Date                                                ...                       \n",
       "2013-01-03 -0.002774  0.003383  0.001086 -0.011407  ... -0.003482 -0.001289   \n",
       "2013-01-04  0.001850 -0.011689  0.002889  0.001657  ...  0.003640 -0.008585   \n",
       "2013-01-07 -0.004632 -0.020406  0.002881 -0.011519  ... -0.001265 -0.008495   \n",
       "2013-01-08 -0.006054 -0.010931 -0.024019 -0.007004  ...  0.002843 -0.004934   \n",
       "2013-01-09 -0.018384  0.012571  0.005510  0.003788  ...  0.009575  0.006082   \n",
       "\n",
       "             SASY.PA   SCHN.PA   SGEF.PA  SIEGn.DE  STLAM.MI   TTEF.PA  \\\n",
       "Date                                                                     \n",
       "2013-01-03 -0.002606 -0.004243  0.004334  0.000716  0.014293 -0.003006   \n",
       "2013-01-04  0.011742 -0.000354  0.003238  0.000834  0.016089 -0.000879   \n",
       "2013-01-07 -0.003944 -0.005865 -0.009610 -0.003700  0.000997 -0.016841   \n",
       "2013-01-08  0.005030  0.000356 -0.002724 -0.006719 -0.012535  0.005857   \n",
       "2013-01-09  0.001490  0.001425  0.011794  0.002045  0.018991  0.003675   \n",
       "\n",
       "            VNAn.DE  VOWG_p.DE  \n",
       "Date                            \n",
       "2013-01-03      NaN  -0.000559  \n",
       "2013-01-04      NaN  -0.000280  \n",
       "2013-01-07      NaN  -0.016348  \n",
       "2013-01-08      NaN  -0.011145  \n",
       "2013-01-09      NaN  -0.013889  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the log-returns dataframe\n",
    "returns = np.log(EuroStoxx50/EuroStoxx50.shift(1))\n",
    "returns = returns.dropna(axis=0, how='all')\n",
    "\n",
    "returns.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Point 0: Variance-Covariance method for VaR and ES in a linear portfolio\n",
    "\n",
    "On the 20th of February 2020 we have an equally weighted portfolio made up of the following equities\n",
    "\n",
    "- Adidas\n",
    "- Allianz\n",
    "- Munich Re\n",
    "- L'Oréal\n",
    "\n",
    "We compute the daily VaR and ES with a 5y estimation using a t-student distribution with 4 degrees\n",
    "of freedom ($\\nu$).\n",
    "The notional of the portfolio is 15 million €. We take a significance level of $\\alpha = 0.99\\%$.\n",
    "\n",
    "Wherever we have missing data due to differing trading days for each stock we substitute the previous\n",
    "day's value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T14:45:05.256181Z",
     "start_time": "2024-03-19T14:45:05.242534Z"
    }
   },
   "outputs": [],
   "source": [
    "# create a dataframe with the relevant time series\n",
    "df_0 = returns[['ADSGn.DE', 'ALVG.DE', 'MUVGn.DE', 'OREP.PA']]\n",
    "# set the date to 20th February 2020\n",
    "valuation_date_0 = datetime(2020, 2, 20)\n",
    "# only use data prior to the valuation date\n",
    "df_0 = df_0[df_0.index < valuation_date_0]\n",
    "# only use the last 5 years\n",
    "df_0 = df_0[df_0.index > valuation_date_0 - pd.DateOffset(years=5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T14:45:05.271183Z",
     "start_time": "2024-03-19T14:45:05.258478Z"
    }
   },
   "outputs": [],
   "source": [
    "# set nu and alpha\n",
    "nu_0 = 4\n",
    "alpha_0 = 0.99\n",
    "notional_0 = 15 * 10**6\n",
    "\n",
    "# estimate the mean vector\n",
    "mean_0 = df_0.mean()\n",
    "# estimate the covariance matrix\n",
    "Cov_0 = df_0.cov()\n",
    "# create the weights vector\n",
    "w_0 = np.array([0.25, 0.25, 0.25, 0.25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daily VaR\n",
    "We compute the daily VaR using the variance-covariance method. The daily VaR is given by:\n",
    "\n",
    "$$\n",
    "VaR_{\\alpha} = \\underbrace{\\bar\\mu \\cdot \\bar\\omega}_{\\mu} + \\underbrace{ \\sqrt{\\bar\\omega^T \\Sigma \\bar\\omega}}_{\\sigma} \\cdot t^{-1}_{\\nu} (\\alpha)\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- $\\bar\\omega$ is the vector of weights of the portfolio\n",
    "- $\\bar\\mu$ is the vector of expected returns of the portfolio\n",
    "- $\\Sigma$ is the variance-covariance matrix of the returns of the portfolio\n",
    "- $t^{-1}_{\\nu}(\\alpha)$ is the $\\alpha$-quantile of the t-student distribution with $\\nu$ degrees of freedom\n",
    "\n",
    "To compute the quantity $t^{-1}_{\\nu}(\\alpha)$ we use the `t.ppf` function from the `scipy.stats` module.\n",
    "\n",
    "See [this stackoverflow answer](https://stackoverflow.com/questions/65468026/norm-ppf-vs-norm-cdf-in-pythons-scipy-stats)\n",
    "and [this documentation](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.t.html#:~:text=ppf(q%2C%20df,cdf%20%E2%80%94%20percentiles).) for more information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T14:45:05.286596Z",
     "start_time": "2024-03-19T14:45:05.274833Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The daily VaR at 99% confidence level is 3.86%\n",
      "The daily VaR at 99% confidence level is 579028.03 EUR\n"
     ]
    }
   ],
   "source": [
    "# find the t_alpha quantile\n",
    "t_alpha = t.ppf(alpha_0, nu_0)\n",
    "\n",
    "# compute the VaR\n",
    "VaR = mean_0 @ w_0 + np.sqrt(w_0 @ Cov_0 @ w_0) * t_alpha\n",
    "\n",
    "print(f'The daily VaR at 99% confidence level is {VaR:.2%}')\n",
    "print(f'The daily VaR at 99% confidence level is {VaR * notional_0:.2f} EUR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daily ES\n",
    "\n",
    "We compute the daily ES using the variance-covariance method. The daily ES is given by:\n",
    "\n",
    "$$\n",
    "ES_{\\alpha} = \\bar\\mu \\cdot \\bar\\omega +\n",
    "    \\sqrt{\\bar\\omega^T \\Sigma \\bar\\omega} \\cdot\n",
    "    \\underbrace{\n",
    "        \\frac{\\nu + ( t^{-1}_{\\nu}(\\alpha) )^2}{\\nu - 1} \\cdot \\frac{ \\phi_{\\nu} (t^{-1}_{\\nu}(\\alpha)) }{1 - \\alpha}\n",
    "    }_{ES_{\\alpha}^{std}}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- $\\bar\\omega$ is the vector of weights of the portfolio\n",
    "- $\\bar\\mu$ is the vector of expected returns of the portfolio\n",
    "- $\\Sigma$ is the variance-covariance matrix of the returns of the portfolio\n",
    "- $t^{-1}_{\\nu}(\\alpha)$ is the $\\alpha$-quantile of the t-student distribution with $\\nu$ degrees of freedom\n",
    "- $\\phi_{\\nu} (\\cdot)$ is the density function of the t-student distribution with $\\nu$ degrees of freedom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T14:45:05.374239Z",
     "start_time": "2024-03-19T14:45:05.352704Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The daily ES at 99% confidence level is 803402.00 EUR\n"
     ]
    }
   ],
   "source": [
    "# compute the ES for the standard t-distribution\n",
    "ES_std = (nu_0 + t_alpha**2) / (nu_0 - 1) * (t.pdf(t_alpha, nu_0) / (1 - alpha_0))\n",
    "\n",
    "# compute the ES for the portfolio\n",
    "ES = mean_0 @ w_0 + np.sqrt(w_0 @ Cov_0 @ w_0) * ES_std\n",
    "\n",
    "print(f'The daily ES at 99% confidence level is {ES * notional_0:.2f} EUR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Point 1: Historical simulation, bootstrap and PCA for VaR and ES in a linear portfolio\n",
    "\n",
    "On the 20th of March 2019 we must compute the following quantitities with $\\alpha = 0.95\\%$:\n",
    "\n",
    "- Portfolio 1: Total (25K shares), AXA (20K shares), Sanofi (20K shares), Volkswagen (10K shares).\n",
    "    We compute the daily VaR and ES with a Historical Simulation and Bootstrap method (with 200 simulations) and a 5 years estimation.\n",
    "- Portfolio 2: Adidas, Airbus, BBVA, BMW and Deutsche Telekom (all equally weighted).\n",
    "    We compute the daily VaR and ES with a 5 year estimation using a Weighted Historical Simulation with $\\lambda = 0.95$.\n",
    "- Portfolio 3: An equally weighted portfolio with shares of the first 18 companies.\n",
    "    We compute the 10 days VaR and ES with a 5 year estimation using a Gaussian parametric PCA approach using the first n principanl components (with n = 1, 2, 3, 4, 5).\n",
    "\n",
    "For each portfolio we also check the Plausibility Check.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data setup\n",
    "We set the parameters for the various models and select the data to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T14:45:05.499645Z",
     "start_time": "2024-03-19T14:45:05.485604Z"
    }
   },
   "outputs": [],
   "source": [
    "# set the parameters\n",
    "alpha_1 = 0.95\n",
    "lmd_1 = 0.94 # lambda is a reserved keyword\n",
    "# set the valuation date to 20th March 2019\n",
    "valuation_date_1 = datetime(2019, 3, 20)\n",
    "\n",
    "# select only the relevant returns\n",
    "df_1 = returns[returns.index <= valuation_date_1]\n",
    "# only use the last 5 years (excluding the valuation date)\n",
    "df_1 = df_1[df_1.index > valuation_date_1 - pd.DateOffset(years=5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Point 1.1 Portfolio 1\n",
    "First of all we set up the weights we will use to compute the various quantities.\n",
    "Recall that portfolio 1 has the following quantities:\n",
    "- Total (25K shares)\n",
    "- AXA (20K shares)\n",
    "- Sanofi (20K shares)\n",
    "- Volkswagen (10K shares)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the relevant indexes\n",
    "df_1_1 = df_1[['TTEF.PA', 'AXAF.PA', 'SASY.PA', 'VOWG_p.DE']]\n",
    "# compute the value at valuation date\n",
    "val_Total = 25_000 * EuroStoxx50.loc[valuation_date_1]['TTEF.PA']\n",
    "val_AXA = 20_000 * EuroStoxx50.loc[valuation_date_1]['AXAF.PA']\n",
    "val_Sanofi = 20_000 * EuroStoxx50.loc[valuation_date_1]['SASY.PA']\n",
    "val_VW = 10_000 * EuroStoxx50.loc[valuation_date_1]['VOWG_p.DE']\n",
    "V_t_1_1 = val_Total + val_AXA + val_Sanofi + val_VW\n",
    "# compute the weights\n",
    "w_1_1 = np.array([val_Total, val_AXA, val_Sanofi, val_VW]) / V_t_1_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Historical Simulation approach\n",
    "\n",
    "In order to apply the Historical Simulation approach we need to compute the losses for each day as:\n",
    "\n",
    "$$\n",
    "L_t = - V_t \\cdot \\omega \\cdot x_t\n",
    "$$\n",
    "\n",
    "then we sort the losses in descending order (the value of index 0 is the highest loss) and we take\n",
    "the $\\alpha$-quantile of the historical losses as $q_{\\alpha, HS} = \\lfloor (1 - \\alpha) \\cdot N \\rfloor$, with \n",
    "$N$ the number of observations.\n",
    "\n",
    "Then we simply take:\n",
    "\n",
    "$$\n",
    "\n",
    "VaR_{\\alpha} =  L^{(q_{\\alpha, HS}, N)} \\\\\n",
    "\n",
    "ES_{\\alpha} = \\frac{1}{q_{\\alpha, HS}} \\sum_{i=1}^{q_{\\alpha, HS}} L^{(i, N)}\n",
    "\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " >--- Historical Simulation ---<\n",
      " alpha = 0.95 V_t = 4731416.99 EUR\n",
      "    -> Daily VaR:   95569.56 EUR\n",
      "    -> Daily ES:   143630.83 EUR\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ES_HS, VaR_HS = HSMeasurements(df_1_1, alpha_1, w_1_1, V_t_1_1, 1)\n",
    "\n",
    "print(f\"\"\"\n",
    " >--- Historical Simulation ---<\n",
    " alpha = {alpha_1} V_t = {V_t_1_1:.2f} EUR\n",
    "    -> Daily VaR: {VaR_HS:>10.2f} EUR\n",
    "    -> Daily ES: {ES_HS:>11.2f} EUR\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrap approach\n",
    "\n",
    "In the bootstrap approach we draw $N$ samples with replacement from the historical losses and we compute the VaR and ES as in the Historical Simulation approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " >--- Bootstrap ---<\n",
      " alpha = 0.95 V_t = 4731416.99 EUR\n",
      "    -> Daily VaR:  100454.42 EUR\n",
      "    -> Daily ES:   174036.41 EUR\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_1_1 = bootstrapStatistical(200, df_1_1)\n",
    "ES_BS, VaR_BS = HSMeasurements(sample_1_1, alpha_1, w_1_1, V_t_1_1, 1)\n",
    "\n",
    "print(f\"\"\"\n",
    " >--- Bootstrap ---<\n",
    " alpha = {alpha_1} V_t = {V_t_1_1:.2f} EUR\n",
    "    -> Daily VaR: {VaR_BS:>10.2f} EUR\n",
    "    -> Daily ES: {ES_BS:>11.2f} EUR\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plausibility Check\n",
    "\n",
    "In order to check wether the VaR and ES we computed are plausible we can use the following formula:\n",
    "\n",
    "$$\n",
    "\n",
    "l_i = VaR_{X_i}(1 - \\alpha) \\quad u_i = VaR_{X_i}(\\alpha) \\\\\n",
    "\n",
    "sVaR_{X_i} = \\underbrace{V_t \\omega_i}_{sens_i} \\cdot \\frac{ |l_i| + |u_i| }{2}\n",
    "\n",
    "$$\n",
    "\n",
    "Where $X_i$ is the $i$-th asset in the portfolio and $\\omega_i$ is the weight of the $i$-th asset in the portfolio.\n",
    "Then the portfolio VaR should be of the following:\n",
    "\n",
    "$$\n",
    "\n",
    "VaR_{\\alpha}^{ptf} = \\sqrt{ \\bar{sVaR}^T \\Sigma \\bar{sVaR} }\n",
    "\n",
    "$$\n",
    "\n",
    "Where $\\bar{sVaR}$ is the vector of the $sVaR$ of each asset in the portfolio and $\\Sigma$ is the variance-covariance matrix of the returns of the portfolio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " >--- Plausibility Check ---<\n",
      "    -> Thumb Rule:     92035.63 EUR\n",
      "    -> Against the HS: 95569.56 EUR\n",
      "    -> Against the BS: 100454.42 EUR\n",
      "\n"
     ]
    }
   ],
   "source": [
    "VaR_PC_1_1 = plausibilityCheck(df_1_1, w_1_1, alpha_1, V_t_1_1, 1)\n",
    "\n",
    "print(f\"\"\"\n",
    " >--- Plausibility Check ---<\n",
    "    -> Thumb Rule: {VaR_PC_1_1:12.2f} EUR\n",
    "    -> Against the HS: {VaR_HS:.2f} EUR\n",
    "    -> Against the BS: {VaR_BS:.2f} EUR\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Point 1.2: Portfolio 2\n",
    "\n",
    "We compute the VaR and ES with a 5 year estimation using the Weighted Historical Simulation. \n",
    "Recall that the Portfolio 2 is composed by: \n",
    "- Adidas\n",
    "- Airbus\n",
    "- BBVA\n",
    "- BMW\n",
    "- Deutsche Telekom\n",
    "all equally weighted. In order to have easier calculations we consider the portfolio weight = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1_2 = df_1[['ADSGn.DE', 'AIR.PA', 'BBVA.MC', 'BMWG.DE', 'DTEGn.DE']]\n",
    "V_t_1_2 = 1\n",
    "w_1_2 = np.array([0.2, 0.2, 0.2, 0.2, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " >--- Weighted Historical Simulation ---<\n",
      " alpha = 0.95 lambda = 0.94\n",
      "    -> Daily VaR:      1.60%\n",
      "    -> Daily ES:       2.16%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# compute the ES and VaR with the Weighted Historical Simulation\n",
    "ES_WHS, VaR_WHS = WHSMeasurements(df_1_2, alpha_1, lmd_1, w_1_2, V_t_1_2, 1)\n",
    "\n",
    "print(f\"\"\"\n",
    " >--- Weighted Historical Simulation ---<\n",
    " alpha = {alpha_1} lambda = {lmd_1}\n",
    "    -> Daily VaR: {VaR_WHS:>10.2%}\n",
    "    -> Daily ES: {ES_WHS:>11.2%}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plausibility Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    >--- Plausibility Check ---<\n",
      "    -> Thumb Rule: 1.92% EUR\n",
      "\n"
     ]
    }
   ],
   "source": [
    "VaR = plausibilityCheck(df_1_2, w_1_2, alpha_1, V_t_1_2, 1)\n",
    "\n",
    "print(f\"\"\"\n",
    "    >--- Plausibility Check ---<\n",
    "    -> Thumb Rule: {VaR:.2%} EUR\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Point 1.3: Portfolio 3\n",
    "\n",
    "We compute the 10 days VaR and ES with a 5 year estimation using a Gaussian parametric PCA approach using the first n principanl components (with n = 1, 2, 3, 4, 5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T14:45:06.245744Z",
     "start_time": "2024-03-19T14:45:06.192851Z"
    }
   },
   "outputs": [],
   "source": [
    "# take the first 18 companies without any NaN values\n",
    "df_1_3 = df_1.dropna(axis=1, how='any').iloc[:, :18]\n",
    "V_t_1_3 = 1\n",
    "w_1_3 = np.ones(18) / 18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA approach\n",
    "\n",
    "We compute the PCA on the returns for each n = 1, 2, 3, 4, 5 and use the first n principal components to compute the VaR and ES."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m yearly_C_1_3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m256\u001b[39m \u001b[38;5;241m*\u001b[39m df_1_3\u001b[38;5;241m.\u001b[39mcov()\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m6\u001b[39m):\n\u001b[1;32m----> 6\u001b[0m     ES_PCA, VaR_PCA \u001b[38;5;241m=\u001b[39m PrincCompAnalysis(yearly_C_1_3, yearly_mu_1_3, w_1_3, \u001b[38;5;241m10\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m256\u001b[39m, alpha_1, i, V_t_1_3)\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124m >--- PCA with n = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ---<\u001b[39m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;124m alpha = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00malpha_1\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;124m    -> Daily VaR: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mVaR_PCA\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m>10.2%\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;124m    -> Daily ES: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mES_PCA\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m>11.2%\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "# compute the ES and VaR with PCA for each n\n",
    "yearly_mu_1_3 = 256 * df_1_3.mean()\n",
    "yearly_C_1_3 = 256 * df_1_3.cov()\n",
    "\n",
    "for i in range(1,6):\n",
    "    ES_PCA, VaR_PCA = PrincCompAnalysis(yearly_C_1_3, yearly_mu_1_3, w_1_3, 10/256, alpha_1, i, V_t_1_3)\n",
    "    print(f\"\"\"\n",
    " >--- PCA with n = {i} ---<\n",
    " alpha = {alpha_1}\n",
    "    -> Daily VaR: {VaR_PCA:>10.2%}\n",
    "    -> Daily ES: {ES_PCA:>11.2%}\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plausibility Check: 5.46%\n"
     ]
    }
   ],
   "source": [
    "# compute the thumb rule\n",
    "VaR = plausibilityCheck(df_1_3, w_1_3, alpha_1, V_t_1_3, 10)\n",
    "\n",
    "print(f\"Plausibility Check: {VaR:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Point 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value of BMWG.DE on 16 Jan 2017 is 86.53 EUR\n"
     ]
    }
   ],
   "source": [
    "# get the value on the 16 Jan 2016 of BMWG.DE\n",
    "val_BMWG = EuroStoxx50.loc[datetime(2017, 1, 16)]['BMWG.DE']\n",
    "print(f'The value of BMWG.DE on 16 Jan 2017 is {val_BMWG:.2f} EUR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POINT 3 - Pricing in case of counterparty risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The observation dates are: [datetime.datetime(2008, 2, 19, 0, 0), datetime.datetime(2009, 2, 19, 0, 0), datetime.datetime(2010, 2, 19, 0, 0), Timestamp('2011-02-21 00:00:00'), Timestamp('2012-02-20 00:00:00'), datetime.datetime(2013, 2, 19, 0, 0), datetime.datetime(2014, 2, 19, 0, 0), datetime.datetime(2015, 2, 19, 0, 0)]\n"
     ]
    }
   ],
   "source": [
    "#Data\n",
    "L = 0.99\n",
    "volatility = 0.2 \n",
    "settlement_date_3 = datetime(2008, 2, 19)\n",
    "observation_dates = [settlement_date_3 + relativedelta(years=i) for i in range(8)]\n",
    "\n",
    "Notional = 30*(10**6)\n",
    "\n",
    "business_days = pd.bdate_range(start=min(observation_dates), end=max(observation_dates))\n",
    "\n",
    "# we want to shuft all the non business days at the next business day\n",
    "for i in range(len(observation_dates)):\n",
    "    if observation_dates[i] not in business_days:\n",
    "        next_business_day = business_days[business_days > observation_dates[i]].min()\n",
    "        observation_dates[i] = next_business_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23221099287770783"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Gaussian simulation\n",
    "mean = 0\n",
    "simul = 1000\n",
    "samples = np.random.normal(mean, np.sqrt(volatility), simul)\n",
    "S = np.zeros(8)\n",
    "S[0] = 1\n",
    "Price = np.zeros(simul)\n",
    "for i in range (simul):\n",
    "    coupons = np.zeros(7)\n",
    "    cumulative_sum = np.zeros(8)\n",
    "    for k in range(7): \n",
    "        S[k+1] = S [k]*np.exp(-volatility**2/2+volatility*samples[i])\n",
    "        coupons[k] = max(0, L*S[k+1]-S[k])\n",
    "    Price[i] = sum(coupons)\n",
    "Final_Price = np.mean(Price)\n",
    "Final_Price"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
